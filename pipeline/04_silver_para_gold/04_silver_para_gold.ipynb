{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "becc9cf1-f164-4143-a9d1-6cdf7aefdf3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_2_table = \"saas_project.core.silver_2_data\"\n",
    "\n",
    "# Puxa Silver 2 tratado direto\n",
    "df_gold = spark.table(silver_2_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30131123-f9fd-4078-941b-207279cb2b23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo CSV final salvo em: /Volumes/saas_project/core/download/gold_data_csv/gold_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Caminho da pasta onde o CSV será salvo\n",
    "output_dir = \"/Volumes/saas_project/core/download/gold_data_csv/\"\n",
    "final_csv_path = os.path.join(output_dir, \"gold_data.csv\")\n",
    "\n",
    "# 1 Remove a coluna VOID que dá erro no CSV\n",
    "df_gold_clean = df_gold.drop(\"source_file\")\n",
    "\n",
    "# 2 Salva o DataFrame em CSV (Spark cria arquivos part-00000...)\n",
    "temp_path = os.path.join(output_dir, \"temp_csv\")\n",
    "df_gold_clean.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(temp_path)\n",
    "\n",
    "# 3 Renomeia o CSV gerado pelo Spark para gold_data.csv\n",
    "for file_name in os.listdir(temp_path):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        temp_csv_file = os.path.join(temp_path, file_name)\n",
    "        shutil.move(temp_csv_file, final_csv_path)\n",
    "        break\n",
    "\n",
    "# 4 Remove a pasta temporária\n",
    "shutil.rmtree(temp_path)\n",
    "\n",
    "print(f\"Arquivo CSV final salvo em: {final_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff821bcd-d408-4df2-805f-7b7b366f22ee",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1771306948826}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>nome</th><th>idade</th><th>email</th><th>cidade</th><th>salario</th><th>ingestion_time</th></tr></thead><tbody><tr><td>1</td><td>Pessoa 0</td><td>26</td><td>user0@exemplo.com</td><td>null</td><td>2036.32</td><td>2026/02/19-18:05:36</td></tr><tr><td>2</td><td>Pessoa 1</td><td>68</td><td>user1@exemplo.com</td><td>Rio</td><td>3705.09</td><td>2026/02/19-18:05:36</td></tr><tr><td>3</td><td>Pessoa 2</td><td>67</td><td>user2@exemplo.com</td><td>São Paulo</td><td>5693.16</td><td>2026/02/19-18:05:36</td></tr><tr><td>4</td><td>Pessoa 3</td><td>38</td><td>user3@exemplo.com</td><td>Belo Horizonte</td><td>9376.51</td><td>2026/02/19-18:05:36</td></tr><tr><td>5</td><td>Pessoa 4</td><td>53</td><td>user4@exemplo.com</td><td>null</td><td>6392.52</td><td>2026/02/19-18:05:36</td></tr><tr><td>6</td><td>Pessoa 5</td><td>49</td><td>user5@exemplo.com</td><td>Rio</td><td>7172.05</td><td>2026/02/19-18:05:36</td></tr><tr><td>7</td><td>Pessoa 6</td><td>null</td><td>user6@exemplo.com</td><td>null</td><td>3802.53</td><td>2026/02/19-18:05:36</td></tr><tr><td>8</td><td>Pessoa 7</td><td>47</td><td>user7@exemplo.com</td><td>null</td><td>4748.2</td><td>2026/02/19-18:05:36</td></tr><tr><td>9</td><td>Pessoa 8</td><td>27</td><td>user8@exemplo.com</td><td>Belo Horizonte</td><td>4476.1</td><td>2026/02/19-18:05:36</td></tr><tr><td>10</td><td>Pessoa 9</td><td>61</td><td>user9@exemplo.com</td><td>null</td><td>9242.02</td><td>2026/02/19-18:05:36</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Pessoa 0",
         "26",
         "user0@exemplo.com",
         null,
         2036.32,
         "2026/02/19-18:05:36"
        ],
        [
         2,
         "Pessoa 1",
         "68",
         "user1@exemplo.com",
         "Rio",
         3705.09,
         "2026/02/19-18:05:36"
        ],
        [
         3,
         "Pessoa 2",
         "67",
         "user2@exemplo.com",
         "São Paulo",
         5693.16,
         "2026/02/19-18:05:36"
        ],
        [
         4,
         "Pessoa 3",
         "38",
         "user3@exemplo.com",
         "Belo Horizonte",
         9376.51,
         "2026/02/19-18:05:36"
        ],
        [
         5,
         "Pessoa 4",
         "53",
         "user4@exemplo.com",
         null,
         6392.52,
         "2026/02/19-18:05:36"
        ],
        [
         6,
         "Pessoa 5",
         "49",
         "user5@exemplo.com",
         "Rio",
         7172.05,
         "2026/02/19-18:05:36"
        ],
        [
         7,
         "Pessoa 6",
         null,
         "user6@exemplo.com",
         null,
         3802.53,
         "2026/02/19-18:05:36"
        ],
        [
         8,
         "Pessoa 7",
         "47",
         "user7@exemplo.com",
         null,
         4748.2,
         "2026/02/19-18:05:36"
        ],
        [
         9,
         "Pessoa 8",
         "27",
         "user8@exemplo.com",
         "Belo Horizonte",
         4476.1,
         "2026/02/19-18:05:36"
        ],
        [
         10,
         "Pessoa 9",
         "61",
         "user9@exemplo.com",
         null,
         9242.02,
         "2026/02/19-18:05:36"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "nome",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "idade",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "email",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "cidade",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salario",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "ingestion_time",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mostra o DataFrame Gold já limpo (sem a coluna VOID)\n",
    "display(df_gold_clean.limit(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "281271a3-2812-48cc-981f-c2d35027c0dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas gravadas com sucesso!\n+--------------------+-------------+---------------+--------------------+\n|            batch_id|total_records|rejected_record|       processing_ts|\n+--------------------+-------------+---------------+--------------------+\n|b501ecb4-17b5-47b...|      1000000|              0|2026-02-19 21:13:...|\n+--------------------+-------------+---------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "import uuid\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# -----------------------------\n",
    "# 1 Cria batch_id único\n",
    "# -----------------------------\n",
    "batch_id = str(uuid.uuid4())\n",
    "\n",
    "# -----------------------------\n",
    "# 2 Calcula métricas\n",
    "# -----------------------------\n",
    "total_records = spark.table(\"saas_project.core.silver_data\").count()\n",
    "valid_records = spark.table(\"saas_project.core.silver_2_data\").count()\n",
    "rejected_records = total_records - valid_records\n",
    "\n",
    "# -----------------------------\n",
    "# 3 Cria DataFrame de métricas de forma compatível com Orquestrador\n",
    "# -----------------------------\n",
    "metrics_df = spark.createDataFrame([\n",
    "    Row(batch_id=batch_id, total_records=total_records, rejected_record=rejected_records)\n",
    "]).withColumn(\"processing_ts\", current_timestamp())\n",
    "\n",
    "# -----------------------------\n",
    "# 4 Salva no Delta com mergeSchema\n",
    "# -----------------------------\n",
    "metrics_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"saas_project.core.silver2_metrics\")\n",
    "\n",
    "print(\"Métricas gravadas com sucesso!\")\n",
    "metrics_df.show(5)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_silver_para_gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}